{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a63a5a-3c5b-4e17-b8cf-8102f455c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c343eff-0586-47b6-9cb8-32a65bf9d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('/home/hari/Documents/MLAI/Datasets/tweet_product_company.csv',encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0eb458d-c0cc-4f4f-af4e-48fa76e46a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display a part of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e107d4-e75a-4ff8-b5aa-de7c13a7ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the necessary columns\n",
    "messages=df[['tweet_text','is_there_an_emotion_directed_at_a_brand_or_product']].copy()\n",
    "messages.columns=['text','response']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2283157-0935-4800-ab43-cf4be0e0bd41",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0501dde-0c73-401b-8b01-42fe0d314ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4eeff1-e148-400f-99cb-c06bef4db049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_hashtags_mentions(text):\n",
    "    cleaned_text = re.sub(r'#\\w+', '', text)\n",
    "    cleaned_text = re.sub(r'@[\\w]*', '', cleaned_text)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'http?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "    \n",
    "import string\n",
    "def remove_punc(text):\n",
    "    punc_free = ''.join([i for i in text if i not in string.punctuation])\n",
    "    return punc_free\n",
    "\n",
    "import nltk\n",
    "def tokenization(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    output = [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lem = WordNetLemmatizer()\n",
    "def lemm(text):\n",
    "    lemm_text = [wordnet_lem.lemmatize(word) for word in text]\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd3dd576-7cdf-4980-b35f-8ddb7c6bbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_col):\n",
    "    corpus = []\n",
    "    for item in df_col:\n",
    "        new_item = remove_hashtags_mentions(item)\n",
    "        new_item = remove_urls(new_item)\n",
    "        new_item = remove_punc(item)\n",
    "        new_item = new_item.lower()\n",
    "        new_item = tokenization(new_item)\n",
    "        new_item = remove_stopwords(new_item)\n",
    "        new_item = lemm(new_item)\n",
    "        corpus.append(' '.join(str(x) for x in new_item))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f60a506-3361-406a-8ae2-1574f3ad81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the text\n",
    "corpus = preprocess(messages['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b51e0b80-8302-4486-8f06-5ddb706557d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding\n",
    "class_mapping = {\n",
    "    'Positive emotion': 2,\n",
    "    'Negative emotion': 0,\n",
    "    'No emotion toward brand or product': 1,\n",
    "    \"I can't tell\": 3\n",
    "}\n",
    "messages['response'] = messages['response'].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ab5b8da-0d0f-4587-8804-ce9b361a3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_one_hot = to_categorical(messages['response'], num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4070dbac-d995-4388-a7e3-2d736c57d2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus, y_one_hot , test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da6c8b3d-ef66-47a6-8576-01d6e4e28e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9955a8f2-905e-45ca-94aa-63929af1ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text and convert to sequences\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52834021-d84d-4381-963e-4fd28705f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to have the same length\n",
    "max_sequence_length = max(len(seq) for seq in X_train_sequences)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756756dc-58c9-40a1-bb55-bfa84ae2dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training data to tensors\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_padded, y_train)).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_padded, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a551b80-653f-4c86-a14f-475a2d9b38a9",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c90c93-55c8-49ea-91c3-0e6b7e4e59bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac8ce780-9e9a-49a0-a976-4851242be765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 26, 100)           918300    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 26, 100)           0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 26, 128)           117248    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 26, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,085,216\n",
      "Trainable params: 1,085,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create a mdel and display the summary\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f0c1910-7083-43fc-8c08-037e581586ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fa41c90-15d5-4276-9fe9-66481c760692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "580c1af9-f1fb-4158-8111-b943aea4db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "228/228 [==============================] - 9s 29ms/step - loss: 0.8918 - accuracy: 0.6079 - val_loss: 0.8400 - val_accuracy: 0.6344\n",
      "Epoch 2/10\n",
      "228/228 [==============================] - 1s 4ms/step - loss: 0.6791 - accuracy: 0.7334 - val_loss: 0.8339 - val_accuracy: 0.6625\n",
      "Epoch 3/10\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.4942 - accuracy: 0.8126 - val_loss: 0.9276 - val_accuracy: 0.6493\n",
      "Epoch 4/10\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.3823 - accuracy: 0.8592 - val_loss: 1.0794 - val_accuracy: 0.6493\n",
      "Epoch 5/10\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.8800 - val_loss: 1.2022 - val_accuracy: 0.6520\n",
      "Epoch 6/10\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.2673 - accuracy: 0.8972 - val_loss: 1.3869 - val_accuracy: 0.6399\n",
      "Epoch 7/10\n",
      "228/228 [==============================] - 1s 3ms/step - loss: 0.2392 - accuracy: 0.9057 - val_loss: 1.5072 - val_accuracy: 0.6471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f708398f710>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10, validation_data=test_dataset,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab59bbf1-fd89-4754-87f0-a6645092f47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 1ms/step - loss: 1.5072 - accuracy: 0.6471\n",
      "Final accuracy:  0.6470588445663452\n"
     ]
    }
   ],
   "source": [
    "# Display the accuray score\n",
    "_, accuracy = model.evaluate(X_test_padded, y_test)\n",
    "print(\"Final accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d19fe7-718e-4aff-9306-38d990345af9",
   "metadata": {},
   "source": [
    "The final accuracy score is **64.7%**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
